{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vae.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNIqI9cqBZwGg27X+gOFVHf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_o-1EHAZjhTG"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","from torchvision.utils import save_image\n","from torchsummary import summary\n","\n","bs = 100\n","# MNIST Dataset\n","train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n","test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AT_wWuUBkxmK","executionInfo":{"status":"ok","timestamp":1607735894077,"user_tz":360,"elapsed":428,"user":{"displayName":"Chandan Chowdary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyNjrLdUjEAEA91Qy62CQcKmxXNIDOt4hUj7RqDQ=s64","userId":"05175208831610953878"}}},"source":["class VAE(nn.Module):\n","    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n","        super(VAE, self).__init__()\n","        \n","        # encoder part\n","        self.fc1 = nn.Linear(x_dim, h_dim1)\n","        self.fc2 = nn.Linear(h_dim1, h_dim2)\n","        self.fc31 = nn.Linear(h_dim2, z_dim)\n","        self.fc32 = nn.Linear(h_dim2, z_dim)\n","        # decoder part\n","        self.fc4 = nn.Linear(z_dim, h_dim2)\n","        self.fc5 = nn.Linear(h_dim2, h_dim1)\n","        self.fc6 = nn.Linear(h_dim1, x_dim)\n","        \n","    def encoder(self, x):\n","        h = F.relu(self.fc1(x))\n","        h = F.relu(self.fc2(h))\n","        return self.fc31(h), self.fc32(h) # mu, log_var\n","    \n","    def sampling(self, mu, log_var):\n","        std = torch.exp(0.5*log_var)\n","        eps = torch.randn_like(std)\n","        return eps.mul(std).add_(mu) # return z sample\n","        \n","    def decoder(self, z):\n","        h = F.relu(self.fc4(z))\n","        h = F.relu(self.fc5(h))\n","        return F.sigmoid(self.fc6(h)) \n","    \n","    def forward(self, x):\n","        mu, log_var = self.encoder(x.view(-1, 784))\n","        z = self.sampling(mu, log_var)\n","        return self.decoder(z), mu, log_var\n","\n","# build model\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXzBFK0FloJM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607735907917,"user_tz":360,"elapsed":10888,"user":{"displayName":"Chandan Chowdary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyNjrLdUjEAEA91Qy62CQcKmxXNIDOt4hUj7RqDQ=s64","userId":"05175208831610953878"}},"outputId":"e2652a2f-6619-4180-b2f6-d3d0ab025400"},"source":["vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n","if torch.cuda.is_available():\n","    vae.cuda()\n","summary(vae, (784,512))\n","print(vae)\n","optimizer = optim.Adam(vae.parameters())\n","# return reconstruction error + KL divergence losses\n","def loss_function(recon_x, x, mu, log_var):\n","    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n","    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n","    return BCE + KLD"],"execution_count":3,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                  [-1, 512]         401,920\n","            Linear-2                  [-1, 256]         131,328\n","            Linear-3                    [-1, 2]             514\n","            Linear-4                    [-1, 2]             514\n","            Linear-5                  [-1, 256]             768\n","            Linear-6                  [-1, 512]         131,584\n","            Linear-7                  [-1, 784]         402,192\n","================================================================\n","Total params: 1,068,820\n","Trainable params: 1,068,820\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.53\n","Forward/backward pass size (MB): 0.02\n","Params size (MB): 4.08\n","Estimated Total Size (MB): 5.63\n","----------------------------------------------------------------\n","VAE(\n","  (fc1): Linear(in_features=784, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=256, bias=True)\n","  (fc31): Linear(in_features=256, out_features=2, bias=True)\n","  (fc32): Linear(in_features=256, out_features=2, bias=True)\n","  (fc4): Linear(in_features=2, out_features=256, bias=True)\n","  (fc5): Linear(in_features=256, out_features=512, bias=True)\n","  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",")\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"viN7_wtYls1u","executionInfo":{"status":"ok","timestamp":1607735911426,"user_tz":360,"elapsed":339,"user":{"displayName":"Chandan Chowdary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyNjrLdUjEAEA91Qy62CQcKmxXNIDOt4hUj7RqDQ=s64","userId":"05175208831610953878"}}},"source":["def train(epoch):\n","    vae.train()\n","    train_loss = 0\n","    for batch_idx, (data, _) in enumerate(train_loader):\n","        data = data.cuda()\n","        optimizer.zero_grad()\n","        \n","        recon_batch, mu, log_var = vae(data)\n","        loss = loss_function(recon_batch, data, mu, log_var)\n","        \n","        loss.backward()\n","        train_loss += loss.item()\n","        optimizer.step()\n","        \n","        if batch_idx % 100 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n","    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Q6OXxJwl4Fy"},"source":["\n","def test():\n","    vae.eval()\n","    test_loss= 0\n","    with torch.no_grad():\n","        for data, _ in test_loader:\n","            data = data.cuda()\n","            recon, mu, log_var = vae(data)\n","            \n","            # sum up batch loss\n","            test_loss += loss_function(recon, data, mu, log_var).item()\n","        \n","    test_loss /= len(test_loader.dataset)\n","    print('====> Test set loss: {:.4f}'.format(test_loss))\n","\n","for epoch in range(1, 1001):\n","    train(epoch)\n","    test()\n","    save_images_to_colab(str(epoch))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iglrhSmFzcct","executionInfo":{"status":"ok","timestamp":1607739268634,"user_tz":360,"elapsed":328,"user":{"displayName":"Chandan Chowdary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyNjrLdUjEAEA91Qy62CQcKmxXNIDOt4hUj7RqDQ=s64","userId":"05175208831610953878"}}},"source":["def save_images_to_colab(i):\n","  with torch.no_grad():\n","      z = torch.randn(4, 2).cuda()\n","      sample = vae.decoder(z).cuda()\n","      sample.view(4, 1, 28, 28)\n","      save_image(sample.view(4, 1, 28, 28), 'vae_'+i+ '.png')"],"execution_count":25,"outputs":[]}]}